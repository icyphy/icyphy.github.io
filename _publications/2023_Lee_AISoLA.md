---
collection: publications
ID: 'Lee:23:Deep'
author: 'Edward A. Lee'
title: 'Deep Neural Networks, Explanations, and Rationality'
booktitle: 'Bridging the Gap Between AI and Reality. AISoLA 2023.'
editor: 'Bernhard Steffen'
volume: 'LNCS 14380'
month: 'December'
publisher: 'Springer'
abstract: '"Rationality" is the principle that humans make decisions on the basis of step-by-step (algorithmic) reasoning using systematic rules of logic. An ideal "explanation" for a decision is a chronicle of the steps used to arrive at the decision. Herb Simon's "bounded rationality" is the observation that the ability of a human brain to handle algorithmic complexity and data is limited. As a consequence, human decision-making in complex cases mixes some rationality with a great deal of intuition, relying more on Daniel Kahnemanâ€™s "System 1" than "System 2." A DNN-based AI, similarly, does not arrive at a decision through a rational process in this sense. An understanding of the mechanisms of the DNN yields little or no insight into any rational explanation for its decisions. The DNN is also operating in a manner more like System 1 than System 2. Humans, however, are quite good at constructing post hoc rationalizations of their intuitive decisions. If we demand rational explanations for AI decisions, engineers will inevitably develop AIs that are very effective at constructing such post hoc rationalizations. With their ability to handle vast amounts of data, the AIs will learn to build rationalizations using many more precedents than any human could, thereby constructing rationalizations for any decision that will become very hard to refute. The demand for explanations, therefore, could backfire, resulting in effectively ceding to the AIs much more power.'
paperurl: 'https://doi.org/10.1007/978-3-031-46002-9_1'
year: '2023'
doi: '10.1007/978-3-031-46002-9_1'
ENTRYTYPE: 'inproceedings'
---

